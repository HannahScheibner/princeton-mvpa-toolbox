= Advanced =



== [ManualAdvancedConventions Conventions] ==

== [ManualAdvancedMemoryManagement Managing memory] ==

=== [ManualAdvancedMemoryManagement#Amount_of_required_RAM Amount of required RAM] ===

== [ManualAdvancedPatternsToDisk Moving patterns to the hard disk] ==


== [ManualAdvancedRemovingObjects Removing objects] ==

== [ManualAdvancedSubjStructureDirectAccess Accessing the subj structure directly] ==


== [ManualAdvancedVoxelLocation Figuring out which voxel is which, and where] ==

== [ManualAdvancedShortcuts Handy shortcuts] ==

== [ManualAdvancedBestPractices Good practices - do's and don't's] ==



=== [ManualAdvancedTroubleshooting Troubleshooting, common errors and debugging] ===

=== Howto's and occasionally-asked questions ===

This contains a set of scenarios that you might run into, and ways to achieve simple goals that might come up in your analysis. In almost all instances, there will be other ways of doing things. These suggested methods are designed to utilise the toolbox functionality to save you work. [#_Contact_details Let us know] if you think you have a better solution than the one provided.


==== Patterns ====


===== What pre-processing should I do' =====

We don't yet have strong recommendations for the pre-processing you should do on your data. Often, people in the Princeton Psychology Department do volume registration/motion correction, despiking, detrending (linear and sometimes quadratic) and sometimes spatial smoothing.

If you find that some kinds of pre-processing steps systematically affect multi-voxel or classification analysis, we'd be very interested to [#_Contact_details hear from you] for future releases.


===== What if I want to use Blah^TM^ to import my patterns' =====

If you want to use a different neuroimaging pre-processing package (e.g. BrainVoyager, SPM) then read the [#_Importing 'Importing'] section to see what importing paths are currently supported. If your package of choice isn't supported, [#_Contact_details let us know]. If you feel like contributing load_blah_pattern.m'' and ''load_blah_mask.m'' import functions, that would be even better. ''

Alternatively, you may find that your favoured package and one of the supported packages can read/write each others' format. AFNI and SPM are both pretty versatile, and many packages are adding support for the new [http://nifti.nimh.nih.gov/ NIfTI] format.

Finally, if you just want to read in data from some other source entirely, then that's easy. As long as you can get the data into Matlab as a 2D (nFeatures x nTimepoints) matrix, then you can simply call [m2html/init_object.html init_object.m''] and then [m2html/set_mat.html ''set_mat.m''] to create a new pattern object and insert your matrix into it. You should also read [:MVPA manual:How do I create a pattern without a mask] if you're going to do this. ''


===== How do I create a pattern without a mask' =====

The toolbox intentionally makes this hard to do. There's a good reason for this ' if you want to know where a feature/voxel in your pattern came from, or find the same voxel in two patterns that have been differently masked, then you need to have a common reference space that you can map between. A pattern without an associated mask contains anonymous, untraceable features.

If that's what you really want, or you just want to try something quick and dirty, the easiest work-around is to just create a place-holder mask:

{{{
>> nFeatures = 100; 

>> subj = init_object(subj,'mask','placeholder');

>> placeholder = ones([1 1 nFeatures]);

>> subj = set_mat(subj,'mask','placeholder',placeholder);

>> subj = init_object(subj,'pattern','my_pattern');

>> subj = set_objfield(subj,'pattern',new_patname,'masked_by','placeholder'); 
}}}


===== How do I figure out which features are common to two patterns' =====

This isn't much harder than finding the common voxels in two masks. Since each pattern has a masked_by'' field, start by extracting the masks used by your two patterns. ''

{{{
>> mask1_name = get_objfield(subj,'pattern','pat1','masked_by'); 

>> mask2_name = get_objfield(subj,'pattern','pat2','masked_by');

>> mask2 = get_mat(subj,'mask','mask2');

>> common_voxels = mask1 & mask2; 
}}}

Now, just refer to ' [:MVPA manual:How do I figure out which voxels are common to two masks] ' to compare the two masks.


===== How do I exclude features from a pattern' =====

Don't just delete the features and then call set_mat.m''. In fact, if you do, it will warn you that the dimensions of the new mat are different. This is an indication that what you are doing isn't a good idea. ''

Instead, you should create a mask with just the features you want, and then create a new pattern that is masked by your new mask. This may seem like a lot of work, but there's a very good reason for it. As discussed in '[#_Figuring_out_which Figuring out which voxel is which, and where]', a pattern doesn't contain any information about its features except their values. If you want to compare voxels from different-sized patterns, or figure out where in the brain the features come from, you need to use a mask as a reference space. That is why every pattern has a masked_by'' field, pointing to a mask with the right number of active voxels. ''

The following snippet should give you an idea of what you need to do, if you want to delete the 100th voxel from the epi_wholebrain'' pattern which is masked by the ''wholebrain'' mask. It first creates a new ''wholebrain2'' mask, sets the 100th voxel in that to 0, then calls [m2html/create_pattern_from_mask.html ''create_pattern_from_mask.m'']'' ''to do the hard work of creating a new ''epi_wholebrain2 ''pattern that will be masked by ''wholebrain2'', and so lack the 100th voxel. ''

{{{
>> subj = duplicate_object(subj,'mask','wholebrain','wholebrain2'); 

>> wholebrain2 = get_mat(subj,'mask','wholebrain2');

>> wb_idx = find(wholebrain2);

>> vox_to_delete = wb_idx(100);

>> wholebrain2(vox_to_delete) = 0;

>> subj = set_mat(subj,'mask','wholebrain2',wholebrain2);

>> subj = create_pattern_from_mask(subj,'epi_wholebrain','wholebrain2','epi_wholebrain2'); 
}}}


===== How do I store a pattern as singles rather than doubles' =====

See [:MVPA manual:How do I store an object as singles rather than doubles].


===== Can the toolbox help me load BRIKs' =====

Even if you're not using most of the toolbox's functionality, it provides wrappers for Ziad Saad's afni_matlab library that might make importing/exporting easier.

If all you want to do is to load in a BRIK, then BrikLoad.m'' in the afni_matlab library is all you need. If you want to load in a BRIK, apply a mask, and end up with a matrix of nVoxels by nTimepoints (as used by the toolbox), then you're probably better off using the toolbox's ''load_afni_pattern.m'' (and ''load_afni_mask.m''). This way, you don't need to worry about indexing, keeping track of which voxel is which or where etc. See ''Advanced / ''[#_Figuring_out_which ''Keeping track of which voxel is which, and where''], for more information. ''

See also: Howtos / Exporting / ''[#_Sometimes_when_using ''Can the toolbox help me write BRIKs]. ''


==== Regressors ====


===== How can I exclude conditions from my analysis' =====

See: Howtos / Pre-classification [:MVPA manual:How can I exclude conditions from my analysis]


===== How can I exclude timepoints from my analysis' =====

See Howtos / Pre-classification / How can I hand


===== How can I take the haemodynamic lag into account' =====

The peak haemodynamic response is estimated to lag about five seconds behind stimulus onset.

1. The very simplest way to take this into account is to shift the regressors matrix a few timepoints along relative to the data, so that the stimulus onset as coded by your regressors aligns with the peak BOLD response in the data. See [How can I shift my regressors along].

2. Better still, you can convolve your regressors matrix with a model of the haemodynamic response function, and then use something like a general linear model to pull out the relative contributions of each condition to the data. See [:MVPA manual:How can I convolve my regressors with a haemodynamic response function]


===== How can I shift my regressors along' =====

See [:MVPA manual:How can I take the haemodynamic lag into account] for background.

[m2html/shift_timepoints.html Shift_regressors.m''] will move the regressors matrix along, snipping off the last few TRs at the end of each run, and zero-padding the very beginning of each run with rest volumes. Assuming a TR (time to repetition) of 2 seconds, then shifting by 3 timepoints is probably about right. ''

subj = shift_regressors(subj,'conds','runs',3);

This will create a new regressors object called shift the regressors in the conds'' object by three timepoints, within each run indexed in the ''runs'' selector object. That is, it will add three rest TRs at the beginning of each run, shifting everything along by three, then then truncate the end by three to leave it the same size. ''

If for some reason you wanted to shift the entire regressors matrix along by n'' timepoints, regardless of which run things came from (probably a bad idea), then just use an all-ones selector instead of a runs selector. ''

For the most part, we recommend [:MVPA manual:convolving the regressors with a haemodynamic response function] and using something like multiple regression for voxel selection. However, if you want to use an ANOVA for your voxel selection, then you need your regressors to be in binary, 1-of-n form, and shifting may be the only option.

See [:Tutorial hard:tutorial_hard] / Shifting the regressors along.


===== How can I convolve my regressors with a haemodynamic response function' =====

See [:MVPA manual:How can I take the haemodynamic lag into account].

The more principled alternative to shifting the regressors is to convolve them with a model of the haemodynamic response function, such as the gamma-variate model used by AFNI's ''waver'' function. You can do this yourself easily enough if you already have your regressors stored in ''.1d'' files. The [m2html/convolve_regressors_afni.html ''convolve_regressors_afni.m''] function writes out a regressors object to separate ''.1d'' files, one for each run for each condition, calls the ''waver'' function to create new convolved ''.1d'' files, reads them in and concatenates them to create a new regressors object, e.g.

{{{ 
>> subj = convolve_regressors_afni(subj,'conds','runs'); 
}}}

These convolved regressors can then be used for voxel selection, classification etc., though obviously they'll no longer be binary. This can make your life a little bit more complicated ' unless you have a slow block design with lots of rest between blocks, it won't be clearcut which conditions each timepoint belongs to any more. Such is life with fMRI. If you're planning to do basic classification, then you're going to have to decide what to do with these timepoints that belong to multiple conditions. Perhaps the simplest thing would be to throw out all the timepoints that belong to multiple conditions. Alternatively, you could use a classifier that will give you scalar-valued outputs (e.g. a neural network with a sigmoidal activation-function hidden layer and a linear activation-function output layer), and feed in the convolved regressors. You could also consider using the beta values from a GLM rather than the actual raw voxel data itself (see Haxby et al., 2001). In short though, if you want to do basic 1-of-n classification, slow block designs are much easier to analyze.

See [:Tutorial hard:tutorial_hard] / Convolving the regressors with a model of the haemodynamic response function''. ''


==== Masks ====


===== How do I figure out which voxels are common to two masks' =====

This is very easy. Since masks are boolean 3D matrices, you could just try:

{{{
>> mask1 = get_mat(subj,'mask','mask1'); 

>> mask2 = get_mat(subj,'mask','mask2');

>> common_voxels = mask1 & mask2; 
}}}

That will produce a third boolean 3D matrix, with 1s where both mask1'' and ''mask2'' had 1s. You could then create a new ''common_voxels'' mask object, and use this to mask a pattern using [m2html/create_pattern_from_mask.html ''create_pattern_from_mask.m'']. ''


===== How do I find the coordinates of active voxels in a mask' =====

The mat'' of a mask object is a 3D boolean object. If you would like an (''nVox'' x ''3'') matrix of ''x''/''y''/''z'' Cartesian coordinates listing those voxels that are active in the volume: ''

{{{
>> mymask = get_mat(subj,'mask','mymaskname'); 

>> [x y z] = ind2sub(size(mymask),find(mymask)); % untested xxx
 }}}


===== How do I create a mask that allows all the features through' (Creating a wholevol mask) =====

The volume collected by the fMRI scanner is a cuboid. Normally, you'll probably only want to include the voxels inside the cranium but you may want a mask that includes absolutely every single one of those voxels, which we will term a 'wholevol' mask. It's often useful to try your voxel selection methods on wholevol masks as a sanity-check. If many of the voxels getting selected are outside the brain, that's a bad sign.

All you need to do is create an all-ones 3D matrix. If your volume is 64x64x40:

{{{
>> wholevol = ones(64,64,40); 

>> subj = init_object(subj,'mask','wholevol');

>> subj = set_mat(subj,'mask','wholevol',wholevol);
 }}}

Then, if you want to load in the data for every single voxel from some BRIK file, then you would call [m2html/load_afni_pattern.html load_afni_pattern.m]'' as before, using 'wholevol' as the mask argument, e.g. ''

{{{
>> for i=1:10 

raw_filenames{i} = sprintf('haxby8_r%i+orig',i);

end

>> subj = load_afni_pattern(subj,'epi','wholevol',raw_filenames); 
}}}

Note: this could involve loading in hundreds of thousands of voxels' worth of data, which will probably be too RAM-intensive to be manageable. There's not a lot you can do about this. Storing the data as singles, rather than doubles is probably a good start ' see [:MVPA manual:How do I store an object as singles rather than double].


===== Creating a wholebrain (intra-cranial) mask, or other anatomical mask =====

Currently, there are no facilities in the toolbox for automatically defining the cranial boundaries to create intra-cranial masks, or for drawing anatomical ROIs. We recommend that you use a function like AFNI's 3dAutomask'' for defining intra-cranial boundaries, or draw the ROIs yourself, save to a BRIK file, and then use ''[m2html/load_afni_mask.html load_afni_mask.m]'' to read that mask in to Matlab. ''

For information about other neuroimaging packages, see [#_Importing Importing]''. ''


==== Pre-classification ====


===== How can I handpick timepoints to exclude from my analysis' =====

Don't delete any timepoints from your patterns or regressors. Instead, just tell [m2html/create_xvalid_indices.html create_xvalid_indices.m]'' to use a selector as a kind of temporal mask to censor out the timepoints you don't want. Imagine you have 1000 TRs, and you want to exclude the 111th (because that's the point in your experiment where Bilbo disappears): ''

{{{
>> nTRs = 1000; 

>> temp_sel= ones(1,nTRs);

>> temp_sel(111) = 0;

>> subj = init_object(subj,'selector','no_bilbo');

>> subj = set_mat(subj,'selector',no_bilbo',temp_sel);

Now, when you call ''create_xvalid_indices.m'', feed in the ''no_bilbo'' selectors object as the ''actives_selname'':

>> subj = create_xvalid_indices(subj,'runs', ...

'actives_selname','no_bilbo');
 }}}

Note: this method will only exclude these timepoints from functions that use the create_xvalid_indices.m''. They still exist in regressors or patterns or other objects. It's just that they will be ignored when creating the cross-validation selector group that gets used for feature selection and classification later on. Early functions like ''zscore_runs.m'' that don't use the cross-validation selector group will still include these timepoints. This is deliberate, since we recommend that you include all your TRs when zscoring. ''

The main advantage of this method is that it doesn't require you to actually delete the TRs that you don't want from your patterns, so that if you change your mind, you can easily rerun your analysis by feeding in a different actives_selname'' selector to ''create_xvalid_indices.m''. ''


===== How can I exclude rest timepoints from my analysis' =====

First, read '[:MVPA manual:How can I handpick timepoints to exclude from my analysis']'.

This time, instead of hand-picking the timepoints to exclude individually, you want to exclude all the timepoints in your regressors matrix that don't have an active condition. As above, this simply involves setting those timepoints in your actives_selname'' selector to 0. For instance: ''

{{{
>> regs = get_mat(subj,'regressors','my_conds'); 

>> temp_sel = ones(1,size(regs,2));

>> temp_sel(find(sum(regs)==0)) = 0;

>> subj = init_object(subj,'selector','no_rest');

>> subj = set_mat(subj,'selector',no_rest',temp_sel);

>> subj = create_xvalid_indices(subj,'runs','actives_selname','no_rest');
 }}}


===== How can I exclude conditions from my analysis' =====

We recommend using the same method as described first in '[#_How_do_I How can I handpick timepoints to exclude from my analysis']' and elaborated in '[#_How_can_I_1 How can I exclude rest timepoints from my analysis']'.

The only difference here is that we are going to create a new regressors matrix with a reduced number of condition-rows beforehand. First, create a new regressors object by duplicating the current set of regressors. Then remove the appropriate condition-rows from the new regressors, and the appropriate condition-name string from the condnames'' field. For example, to create a new regressors object called ''regs_no_3 ''that lacks the third condition from ''regs_original''. ''

{{{
>> subj = duplicate_object(subj,'regressors','regs_original','regs_no_3'); 

>> regs_no_3_mat = get_mat(subj,'regressors','regs_no_3');

>> regs_no_3_mat(3,:) = [];

>> subj = set_mat(subj,'regressors','regs_no_3',regs_no_3_mat);

>> condnames_no_3 = get_objfield(subj,'regressors','regs_no_3','condnames');

>> condnames_no_3(3) = [];

>> subj = set_objfield(subj,'regressors','regs_no_3','condnames',condnames_no_3);
 }}}

Now, regs_no_3'' will contain as many timepoints as ''regs_original'', but fewer condition-rows, and more 'rest timepoints', i.e. timepoints with no active conditions. Now, we can just proceed as described above for [#_How_can_I_1 excluding rest] from your analysis to ensure that those 'rest' timepoints are ignored when generating the statmap and doing classification. In other words, the third condition won't feature at all in any steps of the analysis that use selectors in the group created by ''create_xvalid_indices.m''. ''

Proceeding from now on exactly as described in '[#_How_can_I_1 How can I exclude rest timepoints from my analysis']':

{{{
>> regs = get_mat(subj,'regressors','my_conds'); 

>> temp_sel = ones(1,size(regs_no_3,2));

>> temp_sel(find(sum(regs_no_3)==0)) = 0;

>> subj = init_object(subj,'selector','sel_no_3');

>> subj = set_mat(subj,'selector',sel_no_3',temp_sel);

>> subj = create_xvalid_indices(subj,'runs','actives_selname','sel_no_3'); 
}}}


===== How can I exclude rest and hand-picked timepoints and some conditions' =====

Create a separate boolean temporal mask selector for each, as above. Then create a new selector that is the 'AND' of all of those selectors, and feed that in.


==== Classification ====

[[Anchor(_Classification_1)]]

===== Why is my generalization performance poor' =====

See: [#_Troubleshooting_poor_classification Troubleshooting poor classification performance].


===== How do I find the weights that backprop has learned' =====

If you're using the Mathworks Neural Networks toolbox, they're stored in the net'' (that gets saved to ''results.iterations(i).scratchpad'') object in the 'weight and bias values' section. See the [http://www.mathworks.com/access/helpdesk/help/toolbox/nnet/nnet.shtml Matlab Neural Networks manual] for more information. ''

See the [http://www.ncrg.aston.ac.uk/netlab/ Netlab] mlp.m help (and also [http://www.phys.uni.torun.pl/netlab/mlp.htm here]) for more information about where the Netlab net'' object stores the weights matrix or matrices. ''


===== What if I want to train or test on averaged data' =====

If you want to train and'' test on averaged data, then the easiest thing to do would be to average all of your patterns, regressors and selectors, and just run the analysis as normal with the averaged data. ''

If you're trying to train on single TRs but test on averaged data, things are a little more complicated. There are two main solutions.

1. Implement the averaging inside your training or testing function. This is easy to do.

2. Have one copy of your pattern, regressors and mask that's unaveraged, and one copy that's averaged. Then, you'd have to either hack cross_validation.m, or maybe feed in the data that you want to use in through the extra arguments of the training/testing functions.

If you're planning to do this, let us know and we'll try and help, since averaging definitely helps and this functionality will be useful to others.


===== My classifier sometimes hangs in the srchcha bit of the algorithm ' why' =====

See: http://newsreader.mathworks.com/WebX'50@482.SFQaa3hT5tQ.0@.eefecf2

We've experienced this problem occasionally and we never found a solution. Please [mailto:mvpa-toolbox@googlegroups.com contact us] if you think you're having this problem so that we can help Mathworks debug the problem with as many examples as possible ' better still, let us know if you fix it'

Update [ELN]: Try using a different training function (e.g. trainscg'' instead of ''traincgb'') ' just change the ''alg'' field of the ''class_args'' that you feed into ''cross_validation.m'': ''

{{{
>> class_args.train_funct_name = 'train_bp'; 

>> class_args.test_funct_name = 'test_bp';

>> class_args.nHidden = 0;

>> class_args.alg = 'trainscg';

etc.

>> [subj results] = cross_validation(blahblahblah'); 
}}}

A little more background to what these functions are:

When a network hangs, or never finishes training it is commonly due to the function srchcha.m'' entering into a never-satisfied while-loop. srchcha is a line search function used by the default training algorithm in the toolbox called ''traincgb''. This is a powerful and effective training algorithm that looks for the direction of the steepest gradient and then performs a line search in the direction of that gradient to decide how far in that direction to adjust the weights. ''Traincgb'' is an example of a conjugate training algorithm, meaning it uses information about the direction of steepest descent from previous epochs to guide the learning on the current epoch. Conjugate training algorithms (accoding to Mathworks) converge faster than other training algorithms and thus are nice to use. Another such algorithm is ''trainscg'' ' a major difference however is that this function does not use a line search algorithm to determine the next weight update and thus avoids the problem of hanging nets. ''

See the [http://www.mathworks.com/access/helpdesk/help/toolbox/nnet/backpr14.html#3826 comparison] in the Backpropagation chapter of the [http://www.mathworks.com/access/helpdesk/help/toolbox/nnet/nnet.html Matlab NN toolbox manual] for more information.


===== Why do I sometimes get a divide-by-zero error when training' =====

We believe that this just means that your performance is improving very very slowly with training, and so when the neural network algorithm tries to calculate the gradient of its performance improvement, it's dividing by zero. So, we don't think'' it indicates a major problem. If you want to get rid of it, make your stopping criteria a little more strict, or try the solution described in '[#_My_classifier_sometimes My classifier sometimes hangs in the srchcha bit of the algorithm ' why']'. ''


==== Exporting ====


===== Can the toolbox help me write BRIKs' =====

Even if you're not using most of the toolbox's functionality, it provides wrappers for Ziad Saad's afni_matlab library that might make importing/exporting easier.

If all you want to do is write out a matrix from Matlab into a BRIK, then [m2html/write_to_afni.html write_to_afni.m]'' or ''[m2html/zeroify_write_afni.html zeroify_write_afni.m]'' will probably help, as described in greater detail in their own help and in ''Howtos / Exporting / .

Both of them use an existing sample BRIK of the right resolution and orientation to help create the header the structure. The main difference is that ''write_to_afni.m'' takes in a complete 'subj' structure and pattern/mask name as arguments, while ''zeroify_write_afni.m'' takes the matrix variable itself directly.

These can substantially help you if you're trying to write out BRIKs, since you don't have to worry about headers or anything like that. ''Write_to_afni.m'' is particularly useful if you want to write out an nVoxels x nTimepoints matrix, since it will also figure out where in the brain the voxels in your pattern are.

See also: ''Howtos / Patterns / [#_Masks Can the toolbox help me load BRIKs']''.


===== Sometimes when using write_to_afni.m, I get this message: 'Problem using spoofing write method - trying again with zeroifying - you can safely ignore this message and the following error stack' =====

''[m2html/write_to_afni.m Write_to_afni.m]'' calls ''WriteBrik.m'' (from Ziad Saad's afni_matlab library) to do all the hard work. The complicated part comes when figuring out what should go in the header of the BRIK. There are two ways we've come up with to do this:

1. The ''spoofing'' method

Try and construct a header structure from scratch, based on the parameters and information we have about the pattern. This requires you to also provide the name of an existing BRIK in the same resolution/orientation etc., from which we can borrow any information we don't have. Then, we call ''WriteBrik.m'' to write this out as a BRIK.

''WriteBrik.m'' calls ''CheckBrikHEAD.m'' to ensure that all is well with the header information. More often than not, there is a problem. We are looking into ways to improve this functionality. You can turn off the extra checking in ''CheckBrikHEAD.m'', but this seems like a bad idea, since you'll potentially cause yourself problems when AFNI tries to read the file later.

2. The ''zeroifying'' method

If that first method fails, then it tries a second, more robust but less elegant tactic. It takes the sample BRIK, duplicates it, reads it in using BrikLoad (including the header information), overwrites the loaded matrix with the matrix to be written out, and then uses WriteBrik straight away on the matrix and header information.

This works every time, since it's employing header information from a legitimate BRIK file. However, it involves creating a dummy all-zeros BRIK, and a lot of extra duplicating, loading in and writing out. Also, at the time of writing, much of the functionality allowed by the spoofing method hasn't been implemented for this zeroifying method.

The funny error message that you got with ''write_to_afni.m'' should now make sense. It realised that the first spoofing method failed, and so it's trying the second zeroifying method now.

See the ''[m2html/write_to_afni.html write_to_afni.m]'' and ''[m2html/zeroify_write_afni.html zeroify_write_afni.m]'' help for more information, and also ''Howtos / Exporting / [:MVPA manual:Can the toolbox help me write BRIKs']''.


===== What if I get an out of memory error when trying to write a BRIK' =====

Chances are, you're trying to write a functional BRIK with lots of timepoints. Use the 'runs' optional argument to split the data up into multiple BRIK files by run.


==== Results ====


===== How do I get the testtargs that my classifier was trained on' =====

Inside ''results.iterations(i)'':

· ''test_idx'' tells you *which* TRs were used as test data

· ''created.regsname'' tells you which your regressors object was

So, to get the ''testtargs'' for the first iteration:

{{{
>> i = 1; 

>> regsname = results.iterations(i).created.regsname;

>> conds = get_mat(subj,'regressors',regsname);

>> test_idx = results.iterations(i).test_idx;

>> testtargs = conds(:,test_idx); 
}}}

We could have chosen to save things in more than one place, but instead we decided not to save anything redundantly, but to save *enough* that you could find or generate anything you need.

We plan to implement a plugin function that allows you to change the defaults of what gets saved into the ''results'' structure in the future, so that you could tailor things to make them more convenient for you.


==== Miscellaneous ====


===== What do I do if I start getting memory errors' =====

See ''Advanced / [#_Managing_memory Managing memory]''.


===== How can I slim down the output from ''summarize.m =====

If you have lots of groups, each containing lots of objects, then the output from ''summarize.m'' can be very long. In order to avoid this, there are a couple of ways to slim down its output.

The most obvious is to only display objects of one type. For instance, if you are only interested in ''selector'' objects, you might try the optional 'objtype' argument:

{{{
>> summarize(subj,'objtype','selector') 

Subject 'tutorial_subj' in 'haxby8' experiment

Selectors - [nCond x nTRs]

1) runs - [ 1 x 1210]

2) runs_xval_1 - [GRP size 10] [ 1 x 1210]

3) runs_xval_2 - [GRP size 10] [ 1 x 1210]

4) runs_xval_3 - [GRP size 10] [ 1 x 1210]

5) runs_xval_4 - [GRP size 10] [ 1 x 1210]

6) runs_xval_5 - [GRP size 10] [ 1 x 1210]

7) runs_xval_6 - [GRP size 10] [ 1 x 1210]

8) runs_xval_7 - [GRP size 10] [ 1 x 1210]

9) runs_xval_8 - [GRP size 10] [ 1 x 1210]

10) runs_xval_9 - [GRP size 10] [ 1 x 1210]

11) runs_xval_10 - [GRP size 10] [ 1 x 1210] 
}}}

If you only care which groups exist in the ''subj'' structure, and you're not too interested in the names of the individual objects contained in those groups, then you can specify that the individual members of the groups should not be displayed, e.g.

{{{
>> summarize(subj,'display_groups',false) 

Subject 'tutorial_subj' in 'haxby8' experiment

Patterns -  [ nVox x nTRs]

1) epi - [ 577 x 1210]

2) epi_z - [ 577 x 1210]

3-12) epi_z_statmap * [GRP size 10] [ 577 x 1]

Regressors - [nCond x nTRs]

1) conds - [ 8 x 1210]

Selectors - [nCond x nTRs]

1) runs  - [ 1 x 1210]

2-11) runs_xval * [GRP size 10] [ 1 x 1210]

Masks - [ X x Y x Z ] [ nVox]

1) VT_category-selective  - [ 64 x 64 x 40] [ 577]

2-11) epi_z_thresh * [GRP size 10] [ 64 x 64 x 40] [ V ] 
}}}

* Variable-size groups truncated. See help for display info.

Conversely, setting the 'display_groups' argument to ''true'' will ensure that all the individual members of the groups will be shown.

Often, combining the two arguments can be useful, e.g. if you want to display all the individual members of groups, but only for selectors:

{{{
>> summarize(subj,'display_groups',false,'objtype','selector') 

Subject 'tutorial_subj' in 'haxby8' experiment

Selectors - [nCond x nTRs]

1) runs - [ 1 x 1210]

2-11) runs_xval * [GRP size 10] [ 1 x 1210] 
}}}

By default, ''summarize.m'' tries to be a bit clever ' if you don't have many objects, it will display all the individual members. However, if you have quite a few, then it will concatenate all the ones that have the same sized mat field, but show you individual group members if they differ.


===== How do I store an object as singles rather than doubles' =====

Since the data from the scanner is often fairly noisy, it's rarely necessary to use a ''double'' type to store all the significant figures, which is the default used by Matlab. Storing the data as ''singles'' will use half the number of bytes for each value (4 rather than 8 bytes on most v7 installations).

''Patterns'' tend to be the largest objects. For these, the easiest way to use the ''single'' type is by specifying the optional 'single' argument to be ''true'' when calling ''load_afni_pattern.m'', e.g.

{{{
 >> subj = load_afni_pattern(subj,'epi','mymask','mybrik+orig','single',true); 
}}}

There is no specific mechanism for casting existing objects of other kinds to ''singles'', but here is an example solution for casting a 'runs' selector to be of type ''single'':

{{{
>> runs = get_mat(subj,'selector','runs'); 

>> runs_single = single(runs);

>> >> whos runs*

Name Size Bytes Class

runs  1x1210 9680 double array

runs_single 1x1210 4840 single array

>> subj = set_mat(subj,'selector','runs',runs_single); 
}}}

Note: at the time of writing, some of the core functions for copying objects may not be very smart about ensuring that the new objects' matrices are of the same type as the object they are a duplicate of. Hopefully, at the time of reading, this will have been fixed. All the same, you would be wise when using matrices of ''single'' type that new objects (created with ''init_object.m'' and ''set_mat.m'', or with ''duplicate_object.m'') contain matrices of the right'' ''type.


===== How would I store two subjects' worth of data' =====

At this stage, we haven't agreed upon a convention for storing two subjects' worth of data at the same time. There are lots of reasons one might want to do this, e.g. training on one subject and testing on the other.

There are various approaches to consider:

1. Have two 'subj' structures, e.g. 'subj1' and 'subj2'. After all, although we always name the 'subj' structure 'subj', none of the functions care what it's actually called in your workspace. You'd initialize them something like this:

{{{
>> subj1 = init_subj('multi-subj_experiment','first_subj'); 

>> subj2 = init_subj('multi-subj_experiment','second_subj');

>> subj1 = load_afni_pattern(subj1,'epi','subj_brik1+orig');

>> subj2 = load_afni_pattern(subj2,'epi','subj_brik2+orig'); 
}}}

Now, each 'subj' structure will look like this:

{{{
>> summarize(subj1) 

Subject 'first_subj' in 'multi-subj_experiment' experiment

Patterns - [ nVox x nTRs]

1) epi - [50000 x 1000]

No regressors objects

No selector objects

No mask objects

>> summarize(subj2)

Subject 'second_subj' in 'multi-subj_experiment' experiment

Patterns - [ nVox x nTRs]

1) epi - [60000 x 1000]

No regressors objects

No selector objects

No mask objects 
}}}

and from that point, just use 'subj1' and 'subj2' as your variables. You'll have to write custom functions to replace ''cross_validation.m'' that take in two 'subj' structures though.

{{{
2. Have a single 'subj' structure, as normal, with two epi patterns, e.g. 

>> subj = init_subj('multi-subj_experiment','both_together');

>> subj = load_afni_pattern(subj,'epi_1','subj_brik1+orig');

>> subj = load_afni_pattern(subj,'epi_2','subj_brik2+orig');

>> summarize(subj)

Subject 'both_together' in 'multi-subj_experiment' experiment

Patterns - [ nVox x nTRs]

1) epi_1 - [50000 x 1000]

2) epi_2 -  [60000 x 1000]

No regressors objects

No selector objects

No mask objects 
}}}

You will still need some kind of custom function that takes in two pattern names.

3. Concatenate the two patterns together to form one pattern, and create a custom selector group with 2 members, where you train on one subject's data, and test on the other, and vice versa.

Unfortunately, this requires that both subjects' data have the same number of voxels. This might be appropriate if they had been talairached or flatmapped onto a sphere of the same size. In the case above, where the patterns have different numbers of voxels, we would need a principled way of deciding which voxels to remove. For now, let's simplify and just remove the last 10,000.

Using the same subject called 'both_together' that we created above in approach 2:

{{{
>> epi_1 = get_mat(subj,'pattern','epi_1'); 

>> epi_2 = get_mat(subj,'pattern','epi_2');

>> epi_2 = epi_2(1:50000,:);

>> epi_both = [epi_1 epi_2];

>> size(epi_both)

ans =

50000 2000 

>> subj = initset_object(subj,'pattern','epi_both',epi_both);

Now, we need to create custom selector objects, and make them part of the same group:

>> sel1 = ones(1,2000);

>> sel1(1001:end) = 2;

>> sel2 = ones(1,2000);

>> sel2(1:1000) = 2;

>> subj = initset_object(subj,'selector','two_subjs_xval_1',sel1,'group_name','two_subjs_xval');

>> subj = initset_object(subj,'selector','two_subjs_xval_2',sel2,'group_name','two_subjs_xval'); 
}}}

Now we're ready to call cross_validation as normal:

{{{
 >> [subj results] = cross_validation(subj,'epi_both','conds','two_subjs_xval_2','masks',class_args); 
}}}

Note: in this toy example, we didn't bother to create the 'conds' regressors or the 'masks' masks or the class_args structure, which you would obviously need to do first.

This third approach would be the easiest, since it employs existing functions. However, it's not very flexible, and it involves throwing two subjects' worth of data into a single variable, which seems like a recipe for confusion later.


===== What if I don't want to use Matlab? Are there any alternatives to the MVPA toolbox? =====

At the time of writing, we are aware of 2 recent efforts to help with running multi-voxel pattern analyses:

If you like the idea of multi-voxel pattern analysis, but don't or can't use Matlab, then you may be interested in [http://pkg-exppsy.alioth.debian.org/pymvpa/ PyMVPA]. This is a Python-based toolbox similar in spirit to our Matlab MVPA toolbox, written by Michael Hanke, Yaroslav Halchenko, Per Sederberg and the rest of the Debian Experimental Psychology crew.

Jeffery Prescott and Stephen La''''''Conte's [http://afni.nimh.nih.gov/pub/dist/doc/program_help/3dsvm.html 3dsvm] is a plugin that allows you to run support vector machine analyses from within AFNI.

If you know of any others, [mailto:mvpa-toolbox@googlegroups.com let us know] and we'll update this page.