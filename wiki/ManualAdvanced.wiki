= Advanced =



== [ManualAdvancedConventions Conventions] ==

== [ManualAdvancedMemoryManagement Managing memory] ==

=== [ManualAdvancedMemoryManagement#Amount_of_required_RAM Amount of required RAM] ===

== Moving patterns to the hard disk ==

The [http://www.csbmb.princeton.edu/mvpa/docs/m2html/move_pattern_to_hd.html _move_pattern_to_hd.m_] and its companion, [http://www.csbmb.princeton.edu/mvpa/docs/m2html/load_pattern_from_hd.html _load_pattern_from_hd.m_] are designed to free up RAM without throwing away information. They allow you to move the matrix contents of a particular object out to a file, while allowing you to access that data using the standard _get/set_object_ scripts entirely transparently. This is one of the side-advantages of using the accessor scripts as a layer of abstraction between the toolbox's data structures and you, the user.

If you're having trouble with memory, we recommend that you choose a couple of large pattern objects that you're not using and use _move_pattern_to_hd.m_ on them to free up RAM. Of course, access times for data stored on the hard disk are much, much slower than for data stored in RAM. For this reason, the data can be moved back into RAM (removing any traces from the hard disk) with _load_pattern_from_hd.m_.

In the future, we hope to take advantage of Matlab's memory-mapping functionality or investigate other file formats that will allow more efficient random-access than the .mat format, which requires the entire matrix to be loaded in before it can be accessed. Any advice or support [#_Contact_details would be appreciated].

It is worth noting that this functionality only exists for _patterns_, since they take up so much more space than any of the other data types.

See [tutorial_hard.htm _tutorial_hard_]_ / Moving patterns to the HD for a walkthrough of how to do this_.


== Removing objects ==

There are two ways in which you can remove objects:

 1. [http://www.csbmb.princeton.edu/mvpa/docs/m2html/remove_mat.html _Remove_mat.m_] will set the object's _mat_ to empty. Since this is where each object's main matrix is stored, this is probably taking up most of the room occupied by the object. This is usually sufficient, and has the advantage that it leaves the surrounding _name_ and _header _ information intact, in case other objects want to reference it, and doesn't renumber the cells.
 1. If you really want to, you can remove the entire cell for the object, by passing in 'erase' as the optional argument to [http://www.csbmb.princeton.edu/mvpa/docs/m2html/remove_object.html _remove_object.m_].

Since _patterns_ tend to be the biggest memory hogs, you can also just transparently [#_Moving_patterns_to shift the _pattern_ to the hard disk], which frees up your RAM without thowing away data that might be useful later on. See _Advanced / _ [#_Managing_memory _Managing memory_] for more solutions.


== Accessing the subj structure directly ==

We realise that using the accessor functions is slightly more cumbersome than accessing the contents of the _subj_ structure directly. However, bypassing them can cause many subtle problems and is not recommended.

Having said that, nothing can go wrong if you're just using the standard syntax to view an object, e.g.

>> subj.regressors{5}

It's really only when you change the values in an object that there's a real risk of things getting badly confused amidst the assumptions and interactions between functions. Hopefully, these should all be preserved intact by the provided accessor functions.

We will provide one example of how the accessor scripts can help. If you remove voxels from a _pattern_ by just deleting them from the matrix, this could disrupt all the fragile indexing that is used to determine which voxel is which. In order to avoid this, _set_mat.m_ makes it very difficult to change the dimensions of the _pattern_ matrix, unless you are using the [#_Figuring_out_which authorised masking functionality that preserves the indexing]. Such bugs can be particularly insidious because they may or may not cause errors. In the worst case, your analysis could run without incident, but actually scramble your voxels.

These [#_Handy_shortcuts handy shortcuts] may make your life a little easier.


== Figuring out which voxel is which, and where ==

_Or "Dude, Where's My Voxel'" ' A Guide to Relative Indices in MVPA by Chris Moore_

See also: [#_Masks Howto's / Data structures / Masks].

In a perfect world, patterns stored in MVPA subject structures would be stored in their native space, in full dimensionality. But due to memory contraints and convenience, it is typically prudent to input and store a subset of the data, such as the voxels specified by a whole-brain mask. For this reason, loaded 3D patterns are stored in the _subj_ structure as two dimensional matrices.

It is important to note that the 3D information (xyz coordinates of voxels in a pattern) is _not_ stored in the pattern once it is loaded. Rather, all patterns are associated with the mask that was used in their creation. For instance, when calling _[http://www.csbmb.princeton.edu/mvpa/docs/m2html/load_afni_pattern.html load_afni_pattern.m]_, a required argument is the name of a map in the _subj_ structure used to mask the BRIK. The resulting pattern contains a field, _masked_by_, which points to the mask that contains the 3D information.

The mask should be a boolean mask with the same dimensions as the data in its native space. The order of data in the pattern corresponds to the order of the voxels, such that one could recreate the dataset in its native space with the code:

{{{
>> data = get_mat(subj,'pattern','dataset'); 

>> masked_by = get_objfield(subj,'dataset','masked_by');

>> mask = get_mat(subj,'mask',masked_by);

>> full_data = zeros(size(mask));

>> full_data(find(mask)) = data; 
}}}

Note that this _only_ works for datasets and masks when the mask was used to create the dataset, thus ensuring proper relative indices, and the mask has not been altered in any way. In general, it is a good practice to never modify masks. If you wish to modify a mask, consider creating a duplicate, and modifying the duplicate. If you do modify a mask that was used to create a dataset, you will break the relative indices, and will not be able to recover the XYZ coordinates of each voxel in that pattern. In the worst case, you may not realise that this is the case, and be erroneously indexing your voxels.

Relative indices such as those above (e.g., find(mask)) only work under specific conditions, and can cause problems if not used properly. For instance, if we have a wholebrain data set, and mask it with an anatomical mask, we can create a 2nd pattern. If we then take this pattern and apply a functional mask, we create a 3rd pattern. The relative indices from the 3rd pattern to the 1st and 2nd are different. To avoid this confusion, they are never stored within the _subj_ structure. Relative indices should always be created on the fly between two objects, and never stored.

Relative indices between any two objects can be calculated by finding the intersection of two masks. Thus, when finding the relative indices for a pattern and a mask, the pattern must have a _masked_by_ mask intact. The code for calculating relative indices is as follows:

{{{
>> data = get_mat(subj,'pattern','dataset'); 

>> masked_by = get_objfield(subj,'pattern','dataset','masked_by');

>> mask = get_mat(subj,'mask','masked_by');

>> new_mask = get_mat(subj,'mask','anat_mask');

>> [int ia ib] = intersect(find(mask), find(new_mask));
 }}}

In this example, IA is the index of MASK in NEW_MASK. IB is the inverse, the index of NEW_MASK in MASK. Thus, one could take the relative index, IB, and extract the voxels in DATA that are present in the mask NEW_MASK:

{{{ 
>> new_data = data(IB,:);
 }}}

This is precisely what create_thresh_mask() does. We have included this guide to help users understand how relative indices were meant to work, and to facilitate integrating new functions, but urge the user to use the standard MVPA functions whenever possible. Happy coding.


== Handy shortcuts ==

We've tried to add some minor labour-saving devices to make using the toolbox easier.


=== Getting the latest object names ===

Much of the time, you'll want to look at or use the most recently-created pattern, or run or regressors or mask. Sometimes, it can be a pain to remember or type long object names, and sometimes when writing functions, you may not know in advance what the latest names will be.

To make this easier, the toolbox keeps track of the latest object of each type that was initialized as subj.p, .r, .s and .m. This way, you could type:

{{{
>> get_object(subj,'pattern',subj.p) 

as a bit of a shorthand. 
}}}

Note: this is one of those handy labour-saving devices that might prove a terrible idea if used carelessly. For instance, be careful after creating a group, since it's unlikely that you'll want to specifically access the last item in that group.

Note: We deliberately decided not to have the remove functions alter the subj.x shortcuts when removing the highest-numbered mat or object of its type. This way, if you forget to update them yourself, you'll get an error. If we were to automatically set them to the next highest-numbered item, you might not notice and end up with a subtil and devilish bug.

If you have ideas for other ways to speed up frequently-performed tasks or minimise how much typing users have to do, we'd be happy to [#_Contact_details hear from you].


=== Getting the mat immediately from a duplicated object ===

Often, you'll find yourself doing the following:

1. duplicating an object

2. getting the _mat_ from the new object

3. modifying it

4. setting it back into the object.

To reduce this down by one step, it's worth noting that the [http://www.csbmb.princeton.edu/mvpa/docs/m2html/duplicate_object.html _duplicate_object.m_] function will return the duplicated object's _mat_ as its second argument, allowing you to combine the first two steps in one line:

{{{ 
>> [subj duplicated_mat] = duplicate_obj(subj,objtype,old_objname,new_objname);
 }}}


== Creating custom functions ==

It is very easy to override the toolbox's default functions with your own custom-created function that the main toolbox control functions can call when appropriate. For instance, if you don't want to use the default backpropagation classifier, or the default ANOVA statmap generator, you can drop your own functions in instead, and the toolbox's no-peeking cross-validation control functions will use your custom functions instead at the appropriate times.

At the moment, there are various places where you can substitute your own functions ' click on the links in the [#_Places_that_can list] below to skip to the section where the specific details for each are described.

If you do create a custom function and you think others might benefit from it, we'd really like to [#_Contact_details hear from you] so that we can incorporate it into future releases of the toolbox.


=== Places that can call custom function ===

 * [#_statmap statmap generation] ' _feature_selection.m_ and _peek_feature_selection.m_ can take optional _statmap_funct_ and _statmap_arg_ arguments
 * [#_Creating_your_own classifier training] ' _cross_validation.m_ can take an optional _train_funct_ function name string
 * [#_Creating_your_own classifier test] ' _cross_validation.m_ can take an optional _test_funct_ function name string
 * [#_Creating_your_own classifier performance metrics] ' _cross_validation.m_ can take an optional _perfmet_functs_ cell array of performance metric function name strings


=== Requirements for custom functions that modify the _subj_ structure ===

Any custom functions that modify the _subj_ structure (usually by creating a new object) should fulfil the following requirements, if they're going to be well-behaved toolbox citizens:

· take in a _subj_ structure as their first argument

· return the modified _subj_ structure as their first output argument

· if the custom function creates a new _subj_ structure object, you should add a line to the help comments that says 'Adds the following objects:' and a list of the objects/groups that get created

· if the custom function creates a new _subj_ structure object, you should display something like:

sprintf('Created %s called %s',objtype,objname)

 * should call the [http://www.csbmb.princeton.edu/mvpa/docs/m2html/add_created.html _add_created.m_] with fields for the name of the function and any arguments it takes
 * should call [http://www.csbmb.princeton.edu/mvpa/docs/m2html/add_history.html _add_history.m_] to add a line describing themselves to their own freetext history narrative
 * try and do some error-checking on the inputs, if there are any assumptions that the function makes, to help future users avoid making hard-to-debug booboos


== Optional arguments ==

All of the functions in the toolbox use the same conventions for optional arguments, since they all rely on _[http://www.csbmb.princeton.edu/mvpa/docs/m2html/propval.html propval.m]_. This is a standalone function that makes it very easy to specify what optional arguments a function should accept, in any order, what default arguments it should use if they're not supplied, and with lots of error-checking and warning.

Optional arguments must be supplied in property/value pairs, e.g.

{{{
>> summarize(subj,'display_groups',false) 

Here, the property being specified is 'display_groups' and the value being specified is _false_. Multiple optional arguments can be specified at once, and in any order, e.g.

>> summarize(subj,'display_groups',false,'objtype','selector')

or:

>> summarize(subj,'objtype','selector','display_groups',false)
 }}}

In this case, the property/value pairings are as follows:

||  _Property_ ||  _Value_ ||
||  display_groups ||  false ||
||  objtype ||  'selector' ||


Properties are always strings, and always come first in the pair. Values can be strings, or any other type, and always come second.

By the way, for more information on the [http://www.csbmb.princeton.edu/mvpa/docs/m2html/summarize.html summarize.m] function, see also: [#_Viewing_the_subj Viewing the subj structure] and [:MVPA manual:How can I slim down the output from summarize.m].

In the help for a function, the triple-dot at the end of the function declaration denotes that it takes optional arguments, e.g.

{{{
>> help summarize 

[] = summarize(subj,...)

Below, the help says:

DISPLAY_GROUPS (optional, default = blah) ' blah blah

OBJTYPE (optional, default = blah) ' blah blah
 }}}

In this way, all the allowed optional argument properties will be listed, along with their default values (if they are left unspecified), and what terrible things will be wrought by each.

This is a powerful and flexible mechanism, since it allows us to keep basic function declarations simple if you want to use the defaults, but doesn't restrict the user if they do want to specify niceties.

There is one further way in which optional arguments can be supplied. If calling a function with lots of optional arguments, it can be a pain to specify them all each time. In this case, you can bundle them all together in a structure, and just feed that in. Propval.m will understand and deconstruct the structure in exactly the same way as before, e.g.

{{{
>> summ_args.display_groups = false; 

>> summ_args.objtype = 'selector';

>> summarize(subj,summ_args)
 }}}

See the help for [http://www.csbmb.princeton.edu/mvpa/docs/m2html/propval.html propval.m] for more information.

Note: there is one exception - [http://www.csbmb.princeton.edu/mvpa/docs/m2html/summarize.html summarize.m] has a special single optional boolean argument that determines whether or not to display all the members of a group. This is for the user's convenience, since _summarize.m_ gets called so much, but may be deprecated in future versions.


=== Good practices - do's and don't's ===


==== Don't access the subj structure directly ====

See [ManualAdvanced#Accessing_the_subj_structure_directly Accessing the subj structure directly].

Use the accessor functions in order to evade the ghostly voice that utters 'I told you so' for weeks after tracking down tricky bugs that the accessor functions would have precluded.


==== Lower-case ====

Although we have followed the Matlab convention of referring in the comments help to functions and variables using upper-case, all of the functions, variables and arguments in the toolbox are lower-case.

Try and avoid upper-case whenever using toolbox functions or arguments, since it could cause a bug that might be difficult to trace.


==== Be careful with the subj .x shortcuts ====

We added a facility for [#_Getting_the_latest getting the highest-numbered objects' names], but we're still not sure if this is a good idea. If you rely heavily on this, you may accidentally refer to an unintended object, but it can make life easier too.


==== Recommended early pre-processing ====

See '[#_What_pre-processing_should What pre-processing should I do']'


==== Should I split my experiment up other than by runs? ====

It depends a little. The more runs you have, the higher proportion of your experiment you'll be training on, which is probably a good thing

However, unless I would definitely advise splitting the runs according to your actual experimental design:

- if you were to concatenate runs together, you'd have issues with baseline drift

- if you were to split runs up, then you ought to make sure that you don't end up training and testing on contiguous TRs. Training and testing on contiguous TRs might artificially boost classifier performance. however, if there are big enough rest periods separating the split runs, i can't think of why it would create a problem

In conclusion, if you only have a very small number of runs, it might be worth considering, but I probably wouldn't.


=== Troubleshooting, common errors and debugging ===

==== Undefined function or variable ====

Check your paths are right. If they're not, Matlab won't be able to find the toolbox functions to run them. The [:Setup] instructions tell you how to fix your paths.


==== Unable to read file 'blah': No such file or directory.

Check you're in the same directory as your data files. e.g. if you're trying to run the tutorial and you aren't in the directory that contains the sample data (which has to be [http://www.csbmb.princeton.edu/mvpa/downloads/tutorial_easy.tar.gz downloaded separately]. Matlab's [http://www.mathworks.com/access/helpdesk/help/techdoc/index.html?/access/helpdesk/help/techdoc/ref/cd.html 'cd'] command will help you here.



==== Error using ==> get_number / No ' object called ' ====

The [http://www.csbmb.princeton.edu/mvpa/docs/m2html/trunk/mvpa/core/subj/get_number.html get_number.m] function is one of the central accessor functions that figures out which object you want, based on its name. This error probably means that you've typed something wrong at the command-line or in one of your functions, and that you're trying to get or set an object that doesn't exist. So check for typos, incorrect objtypes etc.


==== Sometimes when using write_to_afni.m, I get this message: 'Problem using spoofing write method - trying again with zeroifying - you can safely ignore this message and the following error stack' ====

[[Anchor(_Sometimes_when_using)]] See Howtos / Exporting / ''[#_Sometimes_when_using ''Sometimes when using write_to_afni.m'']'' ...''. ''


==== Out of memory errors ====

See Advanced / ''[#_Managing_memory ''Managing memory'']. ''


==== Invalid MEX-file error ====

The toolbox uses a small number of MEX files (compiled C files) for speed, e.g. compute_xcorr.c. These have to be compiled separately for each platform - google for 'matlab mex' for more info. We aim to provide .mex files for at least linux and mac. Email mvpa-toolbox@googlegroups.com if you think they're missing from a release.

=== Howto's and occasionally-asked questions ===

This contains a set of scenarios that you might run into, and ways to achieve simple goals that might come up in your analysis. In almost all instances, there will be other ways of doing things. These suggested methods are designed to utilise the toolbox functionality to save you work. [#_Contact_details Let us know] if you think you have a better solution than the one provided.


==== Patterns ====


===== What pre-processing should I do' =====

We don't yet have strong recommendations for the pre-processing you should do on your data. Often, people in the Princeton Psychology Department do volume registration/motion correction, despiking, detrending (linear and sometimes quadratic) and sometimes spatial smoothing.

If you find that some kinds of pre-processing steps systematically affect multi-voxel or classification analysis, we'd be very interested to [#_Contact_details hear from you] for future releases.


===== What if I want to use Blah^TM^ to import my patterns' =====

If you want to use a different neuroimaging pre-processing package (e.g. BrainVoyager, SPM) then read the [#_Importing 'Importing'] section to see what importing paths are currently supported. If your package of choice isn't supported, [#_Contact_details let us know]. If you feel like contributing load_blah_pattern.m'' and ''load_blah_mask.m'' import functions, that would be even better. ''

Alternatively, you may find that your favoured package and one of the supported packages can read/write each others' format. AFNI and SPM are both pretty versatile, and many packages are adding support for the new [http://nifti.nimh.nih.gov/ NIfTI] format.

Finally, if you just want to read in data from some other source entirely, then that's easy. As long as you can get the data into Matlab as a 2D (nFeatures x nTimepoints) matrix, then you can simply call [m2html/init_object.html init_object.m''] and then [m2html/set_mat.html ''set_mat.m''] to create a new pattern object and insert your matrix into it. You should also read [:MVPA manual:How do I create a pattern without a mask] if you're going to do this. ''


===== How do I create a pattern without a mask' =====

The toolbox intentionally makes this hard to do. There's a good reason for this ' if you want to know where a feature/voxel in your pattern came from, or find the same voxel in two patterns that have been differently masked, then you need to have a common reference space that you can map between. A pattern without an associated mask contains anonymous, untraceable features.

If that's what you really want, or you just want to try something quick and dirty, the easiest work-around is to just create a place-holder mask:

{{{
>> nFeatures = 100; 

>> subj = init_object(subj,'mask','placeholder');

>> placeholder = ones([1 1 nFeatures]);

>> subj = set_mat(subj,'mask','placeholder',placeholder);

>> subj = init_object(subj,'pattern','my_pattern');

>> subj = set_objfield(subj,'pattern',new_patname,'masked_by','placeholder'); 
}}}


===== How do I figure out which features are common to two patterns' =====

This isn't much harder than finding the common voxels in two masks. Since each pattern has a masked_by'' field, start by extracting the masks used by your two patterns. ''

{{{
>> mask1_name = get_objfield(subj,'pattern','pat1','masked_by'); 

>> mask2_name = get_objfield(subj,'pattern','pat2','masked_by');

>> mask2 = get_mat(subj,'mask','mask2');

>> common_voxels = mask1 & mask2; 
}}}

Now, just refer to ' [:MVPA manual:How do I figure out which voxels are common to two masks] ' to compare the two masks.


===== How do I exclude features from a pattern' =====

Don't just delete the features and then call set_mat.m''. In fact, if you do, it will warn you that the dimensions of the new mat are different. This is an indication that what you are doing isn't a good idea. ''

Instead, you should create a mask with just the features you want, and then create a new pattern that is masked by your new mask. This may seem like a lot of work, but there's a very good reason for it. As discussed in '[#_Figuring_out_which Figuring out which voxel is which, and where]', a pattern doesn't contain any information about its features except their values. If you want to compare voxels from different-sized patterns, or figure out where in the brain the features come from, you need to use a mask as a reference space. That is why every pattern has a masked_by'' field, pointing to a mask with the right number of active voxels. ''

The following snippet should give you an idea of what you need to do, if you want to delete the 100th voxel from the epi_wholebrain'' pattern which is masked by the ''wholebrain'' mask. It first creates a new ''wholebrain2'' mask, sets the 100th voxel in that to 0, then calls [m2html/create_pattern_from_mask.html ''create_pattern_from_mask.m'']'' ''to do the hard work of creating a new ''epi_wholebrain2 ''pattern that will be masked by ''wholebrain2'', and so lack the 100th voxel. ''

{{{
>> subj = duplicate_object(subj,'mask','wholebrain','wholebrain2'); 

>> wholebrain2 = get_mat(subj,'mask','wholebrain2');

>> wb_idx = find(wholebrain2);

>> vox_to_delete = wb_idx(100);

>> wholebrain2(vox_to_delete) = 0;

>> subj = set_mat(subj,'mask','wholebrain2',wholebrain2);

>> subj = create_pattern_from_mask(subj,'epi_wholebrain','wholebrain2','epi_wholebrain2'); 
}}}


===== How do I store a pattern as singles rather than doubles' =====

See [:MVPA manual:How do I store an object as singles rather than doubles].


===== Can the toolbox help me load BRIKs' =====

Even if you're not using most of the toolbox's functionality, it provides wrappers for Ziad Saad's afni_matlab library that might make importing/exporting easier.

If all you want to do is to load in a BRIK, then BrikLoad.m'' in the afni_matlab library is all you need. If you want to load in a BRIK, apply a mask, and end up with a matrix of nVoxels by nTimepoints (as used by the toolbox), then you're probably better off using the toolbox's ''load_afni_pattern.m'' (and ''load_afni_mask.m''). This way, you don't need to worry about indexing, keeping track of which voxel is which or where etc. See ''Advanced / ''[#_Figuring_out_which ''Keeping track of which voxel is which, and where''], for more information. ''

See also: Howtos / Exporting / ''[#_Sometimes_when_using ''Can the toolbox help me write BRIKs]. ''


==== Regressors ====


===== How can I exclude conditions from my analysis' =====

See: Howtos / Pre-classification [:MVPA manual:How can I exclude conditions from my analysis]


===== How can I exclude timepoints from my analysis' =====

See Howtos / Pre-classification / How can I hand


===== How can I take the haemodynamic lag into account' =====

The peak haemodynamic response is estimated to lag about five seconds behind stimulus onset.

1. The very simplest way to take this into account is to shift the regressors matrix a few timepoints along relative to the data, so that the stimulus onset as coded by your regressors aligns with the peak BOLD response in the data. See [How can I shift my regressors along].

2. Better still, you can convolve your regressors matrix with a model of the haemodynamic response function, and then use something like a general linear model to pull out the relative contributions of each condition to the data. See [:MVPA manual:How can I convolve my regressors with a haemodynamic response function]


===== How can I shift my regressors along' =====

See [:MVPA manual:How can I take the haemodynamic lag into account] for background.

[m2html/shift_timepoints.html Shift_regressors.m''] will move the regressors matrix along, snipping off the last few TRs at the end of each run, and zero-padding the very beginning of each run with rest volumes. Assuming a TR (time to repetition) of 2 seconds, then shifting by 3 timepoints is probably about right. ''

subj = shift_regressors(subj,'conds','runs',3);

This will create a new regressors object called shift the regressors in the conds'' object by three timepoints, within each run indexed in the ''runs'' selector object. That is, it will add three rest TRs at the beginning of each run, shifting everything along by three, then then truncate the end by three to leave it the same size. ''

If for some reason you wanted to shift the entire regressors matrix along by n'' timepoints, regardless of which run things came from (probably a bad idea), then just use an all-ones selector instead of a runs selector. ''

For the most part, we recommend [:MVPA manual:convolving the regressors with a haemodynamic response function] and using something like multiple regression for voxel selection. However, if you want to use an ANOVA for your voxel selection, then you need your regressors to be in binary, 1-of-n form, and shifting may be the only option.

See [:Tutorial hard:tutorial_hard] / Shifting the regressors along.


===== How can I convolve my regressors with a haemodynamic response function' =====

See [:MVPA manual:How can I take the haemodynamic lag into account].

The more principled alternative to shifting the regressors is to convolve them with a model of the haemodynamic response function, such as the gamma-variate model used by AFNI's ''waver'' function. You can do this yourself easily enough if you already have your regressors stored in ''.1d'' files. The [m2html/convolve_regressors_afni.html ''convolve_regressors_afni.m''] function writes out a regressors object to separate ''.1d'' files, one for each run for each condition, calls the ''waver'' function to create new convolved ''.1d'' files, reads them in and concatenates them to create a new regressors object, e.g.

{{{ 
>> subj = convolve_regressors_afni(subj,'conds','runs'); 
}}}

These convolved regressors can then be used for voxel selection, classification etc., though obviously they'll no longer be binary. This can make your life a little bit more complicated ' unless you have a slow block design with lots of rest between blocks, it won't be clearcut which conditions each timepoint belongs to any more. Such is life with fMRI. If you're planning to do basic classification, then you're going to have to decide what to do with these timepoints that belong to multiple conditions. Perhaps the simplest thing would be to throw out all the timepoints that belong to multiple conditions. Alternatively, you could use a classifier that will give you scalar-valued outputs (e.g. a neural network with a sigmoidal activation-function hidden layer and a linear activation-function output layer), and feed in the convolved regressors. You could also consider using the beta values from a GLM rather than the actual raw voxel data itself (see Haxby et al., 2001). In short though, if you want to do basic 1-of-n classification, slow block designs are much easier to analyze.

See [:Tutorial hard:tutorial_hard] / Convolving the regressors with a model of the haemodynamic response function''. ''


==== Masks ====


===== How do I figure out which voxels are common to two masks' =====

This is very easy. Since masks are boolean 3D matrices, you could just try:

{{{
>> mask1 = get_mat(subj,'mask','mask1'); 

>> mask2 = get_mat(subj,'mask','mask2');

>> common_voxels = mask1 & mask2; 
}}}

That will produce a third boolean 3D matrix, with 1s where both mask1'' and ''mask2'' had 1s. You could then create a new ''common_voxels'' mask object, and use this to mask a pattern using [m2html/create_pattern_from_mask.html ''create_pattern_from_mask.m'']. ''


===== How do I find the coordinates of active voxels in a mask' =====

The mat'' of a mask object is a 3D boolean object. If you would like an (''nVox'' x ''3'') matrix of ''x''/''y''/''z'' Cartesian coordinates listing those voxels that are active in the volume: ''

{{{
>> mymask = get_mat(subj,'mask','mymaskname'); 

>> [x y z] = ind2sub(size(mymask),find(mymask)); % untested xxx
 }}}


===== How do I create a mask that allows all the features through' (Creating a wholevol mask) =====

The volume collected by the fMRI scanner is a cuboid. Normally, you'll probably only want to include the voxels inside the cranium but you may want a mask that includes absolutely every single one of those voxels, which we will term a 'wholevol' mask. It's often useful to try your voxel selection methods on wholevol masks as a sanity-check. If many of the voxels getting selected are outside the brain, that's a bad sign.

All you need to do is create an all-ones 3D matrix. If your volume is 64x64x40:

{{{
>> wholevol = ones(64,64,40); 

>> subj = init_object(subj,'mask','wholevol');

>> subj = set_mat(subj,'mask','wholevol',wholevol);
 }}}

Then, if you want to load in the data for every single voxel from some BRIK file, then you would call [m2html/load_afni_pattern.html load_afni_pattern.m]'' as before, using 'wholevol' as the mask argument, e.g. ''

{{{
>> for i=1:10 

raw_filenames{i} = sprintf('haxby8_r%i+orig',i);

end

>> subj = load_afni_pattern(subj,'epi','wholevol',raw_filenames); 
}}}

Note: this could involve loading in hundreds of thousands of voxels' worth of data, which will probably be too RAM-intensive to be manageable. There's not a lot you can do about this. Storing the data as singles, rather than doubles is probably a good start ' see [:MVPA manual:How do I store an object as singles rather than double].


===== Creating a wholebrain (intra-cranial) mask, or other anatomical mask =====

Currently, there are no facilities in the toolbox for automatically defining the cranial boundaries to create intra-cranial masks, or for drawing anatomical ROIs. We recommend that you use a function like AFNI's 3dAutomask'' for defining intra-cranial boundaries, or draw the ROIs yourself, save to a BRIK file, and then use ''[m2html/load_afni_mask.html load_afni_mask.m]'' to read that mask in to Matlab. ''

For information about other neuroimaging packages, see [#_Importing Importing]''. ''


==== Pre-classification ====


===== How can I handpick timepoints to exclude from my analysis' =====

Don't delete any timepoints from your patterns or regressors. Instead, just tell [m2html/create_xvalid_indices.html create_xvalid_indices.m]'' to use a selector as a kind of temporal mask to censor out the timepoints you don't want. Imagine you have 1000 TRs, and you want to exclude the 111th (because that's the point in your experiment where Bilbo disappears): ''

{{{
>> nTRs = 1000; 

>> temp_sel= ones(1,nTRs);

>> temp_sel(111) = 0;

>> subj = init_object(subj,'selector','no_bilbo');

>> subj = set_mat(subj,'selector',no_bilbo',temp_sel);

Now, when you call ''create_xvalid_indices.m'', feed in the ''no_bilbo'' selectors object as the ''actives_selname'':

>> subj = create_xvalid_indices(subj,'runs', ...

'actives_selname','no_bilbo');
 }}}

Note: this method will only exclude these timepoints from functions that use the create_xvalid_indices.m''. They still exist in regressors or patterns or other objects. It's just that they will be ignored when creating the cross-validation selector group that gets used for feature selection and classification later on. Early functions like ''zscore_runs.m'' that don't use the cross-validation selector group will still include these timepoints. This is deliberate, since we recommend that you include all your TRs when zscoring. ''

The main advantage of this method is that it doesn't require you to actually delete the TRs that you don't want from your patterns, so that if you change your mind, you can easily rerun your analysis by feeding in a different actives_selname'' selector to ''create_xvalid_indices.m''. ''


===== How can I exclude rest timepoints from my analysis' =====

First, read '[:MVPA manual:How can I handpick timepoints to exclude from my analysis']'.

This time, instead of hand-picking the timepoints to exclude individually, you want to exclude all the timepoints in your regressors matrix that don't have an active condition. As above, this simply involves setting those timepoints in your actives_selname'' selector to 0. For instance: ''

{{{
>> regs = get_mat(subj,'regressors','my_conds'); 

>> temp_sel = ones(1,size(regs,2));

>> temp_sel(find(sum(regs)==0)) = 0;

>> subj = init_object(subj,'selector','no_rest');

>> subj = set_mat(subj,'selector',no_rest',temp_sel);

>> subj = create_xvalid_indices(subj,'runs','actives_selname','no_rest');
 }}}


===== How can I exclude conditions from my analysis' =====

We recommend using the same method as described first in '[#_How_do_I How can I handpick timepoints to exclude from my analysis']' and elaborated in '[#_How_can_I_1 How can I exclude rest timepoints from my analysis']'.

The only difference here is that we are going to create a new regressors matrix with a reduced number of condition-rows beforehand. First, create a new regressors object by duplicating the current set of regressors. Then remove the appropriate condition-rows from the new regressors, and the appropriate condition-name string from the condnames'' field. For example, to create a new regressors object called ''regs_no_3 ''that lacks the third condition from ''regs_original''. ''

{{{
>> subj = duplicate_object(subj,'regressors','regs_original','regs_no_3'); 

>> regs_no_3_mat = get_mat(subj,'regressors','regs_no_3');

>> regs_no_3_mat(3,:) = [];

>> subj = set_mat(subj,'regressors','regs_no_3',regs_no_3_mat);

>> condnames_no_3 = get_objfield(subj,'regressors','regs_no_3','condnames');

>> condnames_no_3(3) = [];

>> subj = set_objfield(subj,'regressors','regs_no_3','condnames',condnames_no_3);
 }}}

Now, regs_no_3'' will contain as many timepoints as ''regs_original'', but fewer condition-rows, and more 'rest timepoints', i.e. timepoints with no active conditions. Now, we can just proceed as described above for [#_How_can_I_1 excluding rest] from your analysis to ensure that those 'rest' timepoints are ignored when generating the statmap and doing classification. In other words, the third condition won't feature at all in any steps of the analysis that use selectors in the group created by ''create_xvalid_indices.m''. ''

Proceeding from now on exactly as described in '[#_How_can_I_1 How can I exclude rest timepoints from my analysis']':

{{{
>> regs = get_mat(subj,'regressors','my_conds'); 

>> temp_sel = ones(1,size(regs_no_3,2));

>> temp_sel(find(sum(regs_no_3)==0)) = 0;

>> subj = init_object(subj,'selector','sel_no_3');

>> subj = set_mat(subj,'selector',sel_no_3',temp_sel);

>> subj = create_xvalid_indices(subj,'runs','actives_selname','sel_no_3'); 
}}}


===== How can I exclude rest and hand-picked timepoints and some conditions' =====

Create a separate boolean temporal mask selector for each, as above. Then create a new selector that is the 'AND' of all of those selectors, and feed that in.


==== Classification ====

[[Anchor(_Classification_1)]]

===== Why is my generalization performance poor' =====

See: [#_Troubleshooting_poor_classification Troubleshooting poor classification performance].


===== How do I find the weights that backprop has learned' =====

If you're using the Mathworks Neural Networks toolbox, they're stored in the net'' (that gets saved to ''results.iterations(i).scratchpad'') object in the 'weight and bias values' section. See the [http://www.mathworks.com/access/helpdesk/help/toolbox/nnet/nnet.shtml Matlab Neural Networks manual] for more information. ''

See the [http://www.ncrg.aston.ac.uk/netlab/ Netlab] mlp.m help (and also [http://www.phys.uni.torun.pl/netlab/mlp.htm here]) for more information about where the Netlab net'' object stores the weights matrix or matrices. ''


===== What if I want to train or test on averaged data' =====

If you want to train and'' test on averaged data, then the easiest thing to do would be to average all of your patterns, regressors and selectors, and just run the analysis as normal with the averaged data. ''

If you're trying to train on single TRs but test on averaged data, things are a little more complicated. There are two main solutions.

1. Implement the averaging inside your training or testing function. This is easy to do.

2. Have one copy of your pattern, regressors and mask that's unaveraged, and one copy that's averaged. Then, you'd have to either hack cross_validation.m, or maybe feed in the data that you want to use in through the extra arguments of the training/testing functions.

If you're planning to do this, let us know and we'll try and help, since averaging definitely helps and this functionality will be useful to others.


===== My classifier sometimes hangs in the srchcha bit of the algorithm ' why' =====

See: http://newsreader.mathworks.com/WebX'50@482.SFQaa3hT5tQ.0@.eefecf2

We've experienced this problem occasionally and we never found a solution. Please [mailto:mvpa-toolbox@googlegroups.com contact us] if you think you're having this problem so that we can help Mathworks debug the problem with as many examples as possible ' better still, let us know if you fix it'

Update [ELN]: Try using a different training function (e.g. trainscg'' instead of ''traincgb'') ' just change the ''alg'' field of the ''class_args'' that you feed into ''cross_validation.m'': ''

{{{
>> class_args.train_funct_name = 'train_bp'; 

>> class_args.test_funct_name = 'test_bp';

>> class_args.nHidden = 0;

>> class_args.alg = 'trainscg';

etc.

>> [subj results] = cross_validation(blahblahblah'); 
}}}

A little more background to what these functions are:

When a network hangs, or never finishes training it is commonly due to the function srchcha.m'' entering into a never-satisfied while-loop. srchcha is a line search function used by the default training algorithm in the toolbox called ''traincgb''. This is a powerful and effective training algorithm that looks for the direction of the steepest gradient and then performs a line search in the direction of that gradient to decide how far in that direction to adjust the weights. ''Traincgb'' is an example of a conjugate training algorithm, meaning it uses information about the direction of steepest descent from previous epochs to guide the learning on the current epoch. Conjugate training algorithms (accoding to Mathworks) converge faster than other training algorithms and thus are nice to use. Another such algorithm is ''trainscg'' ' a major difference however is that this function does not use a line search algorithm to determine the next weight update and thus avoids the problem of hanging nets. ''

See the [http://www.mathworks.com/access/helpdesk/help/toolbox/nnet/backpr14.html#3826 comparison] in the Backpropagation chapter of the [http://www.mathworks.com/access/helpdesk/help/toolbox/nnet/nnet.html Matlab NN toolbox manual] for more information.


===== Why do I sometimes get a divide-by-zero error when training' =====

We believe that this just means that your performance is improving very very slowly with training, and so when the neural network algorithm tries to calculate the gradient of its performance improvement, it's dividing by zero. So, we don't think'' it indicates a major problem. If you want to get rid of it, make your stopping criteria a little more strict, or try the solution described in '[#_My_classifier_sometimes My classifier sometimes hangs in the srchcha bit of the algorithm ' why']'. ''


==== Exporting ====


===== Can the toolbox help me write BRIKs' =====

Even if you're not using most of the toolbox's functionality, it provides wrappers for Ziad Saad's afni_matlab library that might make importing/exporting easier.

If all you want to do is write out a matrix from Matlab into a BRIK, then [m2html/write_to_afni.html write_to_afni.m]'' or ''[m2html/zeroify_write_afni.html zeroify_write_afni.m]'' will probably help, as described in greater detail in their own help and in ''Howtos / Exporting / .

Both of them use an existing sample BRIK of the right resolution and orientation to help create the header the structure. The main difference is that ''write_to_afni.m'' takes in a complete 'subj' structure and pattern/mask name as arguments, while ''zeroify_write_afni.m'' takes the matrix variable itself directly.

These can substantially help you if you're trying to write out BRIKs, since you don't have to worry about headers or anything like that. ''Write_to_afni.m'' is particularly useful if you want to write out an nVoxels x nTimepoints matrix, since it will also figure out where in the brain the voxels in your pattern are.

See also: ''Howtos / Patterns / [#_Masks Can the toolbox help me load BRIKs']''.


===== Sometimes when using write_to_afni.m, I get this message: 'Problem using spoofing write method - trying again with zeroifying - you can safely ignore this message and the following error stack' =====

''[m2html/write_to_afni.m Write_to_afni.m]'' calls ''WriteBrik.m'' (from Ziad Saad's afni_matlab library) to do all the hard work. The complicated part comes when figuring out what should go in the header of the BRIK. There are two ways we've come up with to do this:

1. The ''spoofing'' method

Try and construct a header structure from scratch, based on the parameters and information we have about the pattern. This requires you to also provide the name of an existing BRIK in the same resolution/orientation etc., from which we can borrow any information we don't have. Then, we call ''WriteBrik.m'' to write this out as a BRIK.

''WriteBrik.m'' calls ''CheckBrikHEAD.m'' to ensure that all is well with the header information. More often than not, there is a problem. We are looking into ways to improve this functionality. You can turn off the extra checking in ''CheckBrikHEAD.m'', but this seems like a bad idea, since you'll potentially cause yourself problems when AFNI tries to read the file later.

2. The ''zeroifying'' method

If that first method fails, then it tries a second, more robust but less elegant tactic. It takes the sample BRIK, duplicates it, reads it in using BrikLoad (including the header information), overwrites the loaded matrix with the matrix to be written out, and then uses WriteBrik straight away on the matrix and header information.

This works every time, since it's employing header information from a legitimate BRIK file. However, it involves creating a dummy all-zeros BRIK, and a lot of extra duplicating, loading in and writing out. Also, at the time of writing, much of the functionality allowed by the spoofing method hasn't been implemented for this zeroifying method.

The funny error message that you got with ''write_to_afni.m'' should now make sense. It realised that the first spoofing method failed, and so it's trying the second zeroifying method now.

See the ''[m2html/write_to_afni.html write_to_afni.m]'' and ''[m2html/zeroify_write_afni.html zeroify_write_afni.m]'' help for more information, and also ''Howtos / Exporting / [:MVPA manual:Can the toolbox help me write BRIKs']''.


===== What if I get an out of memory error when trying to write a BRIK' =====

Chances are, you're trying to write a functional BRIK with lots of timepoints. Use the 'runs' optional argument to split the data up into multiple BRIK files by run.


==== Results ====


===== How do I get the testtargs that my classifier was trained on' =====

Inside ''results.iterations(i)'':

· ''test_idx'' tells you *which* TRs were used as test data

· ''created.regsname'' tells you which your regressors object was

So, to get the ''testtargs'' for the first iteration:

{{{
>> i = 1; 

>> regsname = results.iterations(i).created.regsname;

>> conds = get_mat(subj,'regressors',regsname);

>> test_idx = results.iterations(i).test_idx;

>> testtargs = conds(:,test_idx); 
}}}

We could have chosen to save things in more than one place, but instead we decided not to save anything redundantly, but to save *enough* that you could find or generate anything you need.

We plan to implement a plugin function that allows you to change the defaults of what gets saved into the ''results'' structure in the future, so that you could tailor things to make them more convenient for you.


==== Miscellaneous ====


===== What do I do if I start getting memory errors' =====

See ''Advanced / [#_Managing_memory Managing memory]''.


===== How can I slim down the output from ''summarize.m =====

If you have lots of groups, each containing lots of objects, then the output from ''summarize.m'' can be very long. In order to avoid this, there are a couple of ways to slim down its output.

The most obvious is to only display objects of one type. For instance, if you are only interested in ''selector'' objects, you might try the optional 'objtype' argument:

{{{
>> summarize(subj,'objtype','selector') 

Subject 'tutorial_subj' in 'haxby8' experiment

Selectors - [nCond x nTRs]

1) runs - [ 1 x 1210]

2) runs_xval_1 - [GRP size 10] [ 1 x 1210]

3) runs_xval_2 - [GRP size 10] [ 1 x 1210]

4) runs_xval_3 - [GRP size 10] [ 1 x 1210]

5) runs_xval_4 - [GRP size 10] [ 1 x 1210]

6) runs_xval_5 - [GRP size 10] [ 1 x 1210]

7) runs_xval_6 - [GRP size 10] [ 1 x 1210]

8) runs_xval_7 - [GRP size 10] [ 1 x 1210]

9) runs_xval_8 - [GRP size 10] [ 1 x 1210]

10) runs_xval_9 - [GRP size 10] [ 1 x 1210]

11) runs_xval_10 - [GRP size 10] [ 1 x 1210] 
}}}

If you only care which groups exist in the ''subj'' structure, and you're not too interested in the names of the individual objects contained in those groups, then you can specify that the individual members of the groups should not be displayed, e.g.

{{{
>> summarize(subj,'display_groups',false) 

Subject 'tutorial_subj' in 'haxby8' experiment

Patterns -  [ nVox x nTRs]

1) epi - [ 577 x 1210]

2) epi_z - [ 577 x 1210]

3-12) epi_z_statmap * [GRP size 10] [ 577 x 1]

Regressors - [nCond x nTRs]

1) conds - [ 8 x 1210]

Selectors - [nCond x nTRs]

1) runs  - [ 1 x 1210]

2-11) runs_xval * [GRP size 10] [ 1 x 1210]

Masks - [ X x Y x Z ] [ nVox]

1) VT_category-selective  - [ 64 x 64 x 40] [ 577]

2-11) epi_z_thresh * [GRP size 10] [ 64 x 64 x 40] [ V ] 
}}}

* Variable-size groups truncated. See help for display info.

Conversely, setting the 'display_groups' argument to ''true'' will ensure that all the individual members of the groups will be shown.

Often, combining the two arguments can be useful, e.g. if you want to display all the individual members of groups, but only for selectors:

{{{
>> summarize(subj,'display_groups',false,'objtype','selector') 

Subject 'tutorial_subj' in 'haxby8' experiment

Selectors - [nCond x nTRs]

1) runs - [ 1 x 1210]

2-11) runs_xval * [GRP size 10] [ 1 x 1210] 
}}}

By default, ''summarize.m'' tries to be a bit clever ' if you don't have many objects, it will display all the individual members. However, if you have quite a few, then it will concatenate all the ones that have the same sized mat field, but show you individual group members if they differ.


===== How do I store an object as singles rather than doubles' =====

Since the data from the scanner is often fairly noisy, it's rarely necessary to use a ''double'' type to store all the significant figures, which is the default used by Matlab. Storing the data as ''singles'' will use half the number of bytes for each value (4 rather than 8 bytes on most v7 installations).

''Patterns'' tend to be the largest objects. For these, the easiest way to use the ''single'' type is by specifying the optional 'single' argument to be ''true'' when calling ''load_afni_pattern.m'', e.g.

{{{
 >> subj = load_afni_pattern(subj,'epi','mymask','mybrik+orig','single',true); 
}}}

There is no specific mechanism for casting existing objects of other kinds to ''singles'', but here is an example solution for casting a 'runs' selector to be of type ''single'':

{{{
>> runs = get_mat(subj,'selector','runs'); 

>> runs_single = single(runs);

>> >> whos runs*

Name Size Bytes Class

runs  1x1210 9680 double array

runs_single 1x1210 4840 single array

>> subj = set_mat(subj,'selector','runs',runs_single); 
}}}

Note: at the time of writing, some of the core functions for copying objects may not be very smart about ensuring that the new objects' matrices are of the same type as the object they are a duplicate of. Hopefully, at the time of reading, this will have been fixed. All the same, you would be wise when using matrices of ''single'' type that new objects (created with ''init_object.m'' and ''set_mat.m'', or with ''duplicate_object.m'') contain matrices of the right'' ''type.


===== How would I store two subjects' worth of data' =====

At this stage, we haven't agreed upon a convention for storing two subjects' worth of data at the same time. There are lots of reasons one might want to do this, e.g. training on one subject and testing on the other.

There are various approaches to consider:

1. Have two 'subj' structures, e.g. 'subj1' and 'subj2'. After all, although we always name the 'subj' structure 'subj', none of the functions care what it's actually called in your workspace. You'd initialize them something like this:

{{{
>> subj1 = init_subj('multi-subj_experiment','first_subj'); 

>> subj2 = init_subj('multi-subj_experiment','second_subj');

>> subj1 = load_afni_pattern(subj1,'epi','subj_brik1+orig');

>> subj2 = load_afni_pattern(subj2,'epi','subj_brik2+orig'); 
}}}

Now, each 'subj' structure will look like this:

{{{
>> summarize(subj1) 

Subject 'first_subj' in 'multi-subj_experiment' experiment

Patterns - [ nVox x nTRs]

1) epi - [50000 x 1000]

No regressors objects

No selector objects

No mask objects

>> summarize(subj2)

Subject 'second_subj' in 'multi-subj_experiment' experiment

Patterns - [ nVox x nTRs]

1) epi - [60000 x 1000]

No regressors objects

No selector objects

No mask objects 
}}}

and from that point, just use 'subj1' and 'subj2' as your variables. You'll have to write custom functions to replace ''cross_validation.m'' that take in two 'subj' structures though.

{{{
2. Have a single 'subj' structure, as normal, with two epi patterns, e.g. 

>> subj = init_subj('multi-subj_experiment','both_together');

>> subj = load_afni_pattern(subj,'epi_1','subj_brik1+orig');

>> subj = load_afni_pattern(subj,'epi_2','subj_brik2+orig');

>> summarize(subj)

Subject 'both_together' in 'multi-subj_experiment' experiment

Patterns - [ nVox x nTRs]

1) epi_1 - [50000 x 1000]

2) epi_2 -  [60000 x 1000]

No regressors objects

No selector objects

No mask objects 
}}}

You will still need some kind of custom function that takes in two pattern names.

3. Concatenate the two patterns together to form one pattern, and create a custom selector group with 2 members, where you train on one subject's data, and test on the other, and vice versa.

Unfortunately, this requires that both subjects' data have the same number of voxels. This might be appropriate if they had been talairached or flatmapped onto a sphere of the same size. In the case above, where the patterns have different numbers of voxels, we would need a principled way of deciding which voxels to remove. For now, let's simplify and just remove the last 10,000.

Using the same subject called 'both_together' that we created above in approach 2:

{{{
>> epi_1 = get_mat(subj,'pattern','epi_1'); 

>> epi_2 = get_mat(subj,'pattern','epi_2');

>> epi_2 = epi_2(1:50000,:);

>> epi_both = [epi_1 epi_2];

>> size(epi_both)

ans =

50000 2000 

>> subj = initset_object(subj,'pattern','epi_both',epi_both);

Now, we need to create custom selector objects, and make them part of the same group:

>> sel1 = ones(1,2000);

>> sel1(1001:end) = 2;

>> sel2 = ones(1,2000);

>> sel2(1:1000) = 2;

>> subj = initset_object(subj,'selector','two_subjs_xval_1',sel1,'group_name','two_subjs_xval');

>> subj = initset_object(subj,'selector','two_subjs_xval_2',sel2,'group_name','two_subjs_xval'); 
}}}

Now we're ready to call cross_validation as normal:

{{{
 >> [subj results] = cross_validation(subj,'epi_both','conds','two_subjs_xval_2','masks',class_args); 
}}}

Note: in this toy example, we didn't bother to create the 'conds' regressors or the 'masks' masks or the class_args structure, which you would obviously need to do first.

This third approach would be the easiest, since it employs existing functions. However, it's not very flexible, and it involves throwing two subjects' worth of data into a single variable, which seems like a recipe for confusion later.


===== What if I don't want to use Matlab? Are there any alternatives to the MVPA toolbox? =====

At the time of writing, we are aware of 2 recent efforts to help with running multi-voxel pattern analyses:

If you like the idea of multi-voxel pattern analysis, but don't or can't use Matlab, then you may be interested in [http://pkg-exppsy.alioth.debian.org/pymvpa/ PyMVPA]. This is a Python-based toolbox similar in spirit to our Matlab MVPA toolbox, written by Michael Hanke, Yaroslav Halchenko, Per Sederberg and the rest of the Debian Experimental Psychology crew.

Jeffery Prescott and Stephen La''''''Conte's [http://afni.nimh.nih.gov/pub/dist/doc/program_help/3dsvm.html 3dsvm] is a plugin that allows you to run support vector machine analyses from within AFNI.

If you know of any others, [mailto:mvpa-toolbox@googlegroups.com let us know] and we'll update this page.